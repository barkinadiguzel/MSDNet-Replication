# ğŸŒŒ MSDNet Replication â€“ Sample-Level Early Exits for Resource-Efficient Classification

This repository provides a **PyTorch-based replication** of  
**Multi-Scale Dense Networks (MSDNet) â€“ Resource-Efficient Image Classification**.

The focus is **understanding MSDNet sample-level early exit**,  
rather than fully training models or maximizing benchmark accuracy.

- Multi-scale CNN backbone with **dense connections** ğŸ”—  
- **Sample-level early exits** ğŸ¹ for adaptive computation  
- Confidence-based exit thresholds for **computation reduction** âš¡  
- Demonstrates theoretical **efficiency vs accuracy trade-off** ğŸŒ¿  

**Paper reference:** [MSDNet: Multi-Scale Dense Networks](https://arxiv.org/abs/1703.09844) ğŸ”

---

## â›ºï¸ Overview â€“ MSDNet Architecture

![MSDNet Example](images/figmix.jpg)

### ğŸŒ± High-level Pipeline

1. **Input image**

```math
X \in \mathbb{R}^{B \times 3 \times H \times W} 
```

2. **Initial convolution per scale**

```math
F^{(0)}_s = Conv(X), \quad s=1..S 
```

3. **Multi-scale dense blocks**

```math
F^{(l)}_s = MultiScaleBlock(F^{(l-1)}_1, ..., F^{(l-1)}_S), \quad l=1..L 
```

4. **Sample-level early exit classifier**

```math
\hat{Y}_b = 
\begin{cases} 
FC(F^{(l)}_S) & \text{if } \max(\text{softmax}(FC(F^{(l)}_S))) \ge \tau_l \\
\text{next layer} & \text{otherwise}
\end{cases} 
```

> $$\tau_l$$ is the confidence threshold for layer $$l$$, ensuring each sample exits adaptively.

---

## ğŸŒ¿ What the Model Demonstrates

- **Multi-scale blocks**: extract features at different resolutions ğŸŒ¸  
- **Dense connectivity**: reuse features across layers ğŸ”—  
- **Sample-level early exit**: each input may exit at different layers ğŸ¹  
- **Adaptive computation**: reduce FLOPs for easy examples âš¡  
- **Forward-only**: theoretical replication; no training conducted ğŸ§ª  

---

## ğŸ“¦ Repository Structure

```bash
MSDNet-Replication/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ conv_block.py          
â”‚   â”‚   â”œâ”€â”€ activation.py          
â”‚   â”‚   â”œâ”€â”€ normalization.py      
â”‚   â”‚   â””â”€â”€ pooling.py             
â”‚   â”‚
â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â””â”€â”€ multi_scale_blocks.py 
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ msdnet.py         
â”‚   â”‚
â”‚   â”œâ”€â”€ classifiers/
â”‚   â”‚   â””â”€â”€ early_exit.py          
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ cost_estimation.py     
â”‚   â”‚
â”‚   â”œâ”€â”€ loss/
â”‚   â”‚   â””â”€â”€ msdnet_loss.py       
â”‚   â”‚
â”‚   â””â”€â”€ config.py                 
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
